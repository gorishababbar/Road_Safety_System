{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a930f96-6c69-41c9-bc77-0acd898eafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python numpy tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428f64fe-02b1-41f6-a4f0-2e02d28c84d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f03db-be1f-4ec6-8afe-018a3c49d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Enable GPU memory growth (optional, prevents memory crashes)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# Check GPU device\n",
    "print(\"Using GPU:\", tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4e9d2a1-6174-4a00-a13a-66c1539955eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing category: Abuse\n",
      "Processing category: Arrest\n",
      "Processing category: Arson\n",
      "Processing category: Assault\n",
      "Processing category: Burglary\n",
      "Processing category: Explosion\n",
      "Processing category: Fighting\n",
      "Processing category: Normal-Videos-Part-1\n",
      "Feature extraction completed and saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import pickle\n",
    "\n",
    "# Define paths\n",
    "FRAME_DIR = \"extracted_frames\"  # Change to your actual path\n",
    "IMAGE_SIZE = (224, 224)\n",
    "SKIP_FRAMES = 100  # Skip every 100th frame\n",
    "\n",
    "# Load pre-trained ResNet50 model (without top layer)\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "# Function to preprocess and extract features from images\n",
    "def extract_features():\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name in os.listdir(FRAME_DIR):\n",
    "        class_path = os.path.join(FRAME_DIR, class_name)\n",
    "        \n",
    "        if os.path.isdir(class_path):  # Check if it's a folder\n",
    "            print(f\"Processing category: {class_name}\")\n",
    "            \n",
    "            images = sorted(os.listdir(class_path))  # Sort to maintain sequence\n",
    "            \n",
    "            for idx, image_name in enumerate(images):\n",
    "                if idx % SKIP_FRAMES != 0:  # Skip frames\n",
    "                    continue\n",
    "                \n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                \n",
    "                # Read image\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                \n",
    "                img = cv2.resize(img, IMAGE_SIZE)  # Resize to 224x224\n",
    "                img = img_to_array(img)  # Convert to array\n",
    "                img = preprocess_input(img)  # Normalize\n",
    "                \n",
    "                # Extract features\n",
    "                img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "                feature = model.predict(img, verbose=0)[0]  # Extract feature\n",
    "                \n",
    "                features.append(feature)\n",
    "                labels.append(class_name)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Run feature extraction\n",
    "features, labels = extract_features()\n",
    "\n",
    "# Save features & labels for future training\n",
    "with open(\"features.pkl\", \"wb\") as f:\n",
    "    pickle.dump((features, labels), f)\n",
    "\n",
    "print(\"Feature extraction completed and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff56b92-48f3-441f-a399-a15d9ee2c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared! ğŸš€\n",
      "Training samples: 4517, Testing samples: 1130\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load extracted features\n",
    "with open(\"features.pkl\", \"rb\") as f:\n",
    "    features, labels = pickle.load(f)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "import numpy as np\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data prepared! ğŸš€\")\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5808463f-4d56-4ce5-abe9-ed182395963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 99.91% âœ…\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVM Accuracy: {accuracy * 100:.2f}% âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7264f678-0347-493f-8b36-aab99854dc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8504 - loss: 0.4933 - val_accuracy: 0.9973 - val_loss: 0.0086\n",
      "Epoch 2/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0138 - val_accuracy: 0.9973 - val_loss: 0.0075\n",
      "Epoch 3/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0200 - val_accuracy: 0.9973 - val_loss: 0.0114\n",
      "Epoch 4/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0098 - val_accuracy: 0.9982 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0057 - val_accuracy: 0.9991 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.9973 - val_loss: 0.0095\n",
      "Epoch 7/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0136 - val_accuracy: 0.9991 - val_loss: 0.0109\n",
      "Epoch 8/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0180 - val_accuracy: 0.9991 - val_loss: 0.0067\n",
      "Epoch 9/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0339 - val_accuracy: 0.9991 - val_loss: 0.0195\n",
      "Epoch 10/10\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0135 - val_accuracy: 0.9982 - val_loss: 0.0130\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0247   \n",
      "ğŸ¯ MLP Accuracy: 99.82% âœ…\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Build the model with correct input shape\n",
    "model = Sequential([\n",
    "    Input(shape=(features.shape[1],)),  # Correct way to define input shape\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(set(y_train)), activation='softmax')  # Adjust output size dynamically\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"ğŸ¯ MLP Accuracy: {acc * 100:.2f}% âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1177d9f0-c5d8-4831-b6c8-6fbe9bb32f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "513af01a-98e2-4802-bc26-b78365c683af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)  # Convert labels to numbers\n",
    "\n",
    "# Save label mappings\n",
    "np.save(\"label_classes.npy\", label_encoder.classes_)  # Save label names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b1c54db-8131-4651-91cc-06b2ba410892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Actual Category: Fighting\n",
      "Predicted Category: Fighting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the trained classification model\n",
    "model = load_model(\"trained_model.keras\", compile=False)  # Use the correct model format\n",
    "\n",
    "# Load the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load(\"label_classes.npy\", allow_pickle=True)\n",
    "\n",
    "# Load the same feature extractor (e.g., ResNet50) that was used during training\n",
    "feature_extractor = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "# Path to test images\n",
    "TEST_FOLDER = \"extracted_frames\"\n",
    "\n",
    "# Choose a random category and image\n",
    "random_category = np.random.choice(os.listdir(TEST_FOLDER))\n",
    "random_category_path = os.path.join(TEST_FOLDER, random_category)\n",
    "random_image = np.random.choice(os.listdir(random_category_path))\n",
    "random_image_path = os.path.join(random_category_path, random_image)\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = cv2.imread(random_image_path)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = preprocess_input(img)\n",
    "img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Extract features using the pre-trained model\n",
    "features = feature_extractor.predict(img)\n",
    "\n",
    "# Make a prediction using the classifier\n",
    "prediction = model.predict(features)\n",
    "predicted_class = label_encoder.inverse_transform([np.argmax(prediction)])[0]\n",
    "\n",
    "# Display results\n",
    "print(f\"Actual Category: {random_category}\")\n",
    "print(f\"Predicted Category: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc5d0113-e7ff-4e86-af63-9f6a2cab8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy: 0.9982\n",
      "Precision: 0.9982\n",
      "Recall: 0.9982\n",
      "F1 Score: 0.9982\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00       141\n",
      "           2       1.00      1.00      1.00       241\n",
      "           3       1.00      0.96      0.98        27\n",
      "           4       1.00      0.99      1.00       101\n",
      "           5       1.00      1.00      1.00       275\n",
      "           6       0.99      1.00      0.99        72\n",
      "           7       1.00      1.00      1.00       208\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      0.99      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Predict class labels\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Print classification report for detailed breakdown\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f4c5f-b9f7-4cf2-9dfe-0543737fa745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
